time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=1, tm_min=27, tm_sec=53, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.3634229898452759, 'f1': 0.6874588235294118}

#Kaggle code locally
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=13, tm_min=46, tm_sec=49, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.3778288960456848, 'f1': 0.6862925802917804}

#New embedding format of Kaggle code
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=14, tm_min=54, tm_sec=38, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.38060420751571655, 'f1': 0.687872579319605}

Changed embedding creation by not dividing every word by len(embedding)
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=15, tm_min=44, tm_sec=40, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.38060420751571655, 'f1': 0.687872579319605}

Changed seed from 42 -> 22
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=18, tm_min=15, tm_sec=27, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.3729017376899719, 'f1': 0.6868138934028549}

Rerunning 42 seed model with embedding changes.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=21, tm_min=36, tm_sec=3, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.36591261625289917, 'f1': 0.6883146659941075}

Added Word2Vec embeddings for missing words ONLY. Try adding it to present words later. Also, new contractions like the previous run.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=21, tm_hour=22, tm_min=51, tm_sec=54, tm_wday=0, tm_yday=21, tm_isdst=0)
{'threshold': 0.39225447177886963, 'f1': 0.6877264282396656}

Removed new contractions. Rest same as previous.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=22, tm_hour=0, tm_min=17, tm_sec=36, tm_wday=1, tm_yday=22, tm_isdst=0)
{'threshold': 0.383318156003952, 'f1': 0.688061113803688}

Word2Vec with old embeddings. Check run before running pos experiments.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=26, tm_hour=18, tm_min=39, tm_sec=9, tm_wday=5, tm_yday=26, tm_isdst=0)
{'threshold': 0.383318156003952, 'f1': 0.688061113803688}

Updated misspellings to commmon errors.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=26, tm_hour=19, tm_min=41, tm_sec=19, tm_wday=5, tm_yday=26, tm_isdst=0)
{'threshold': 0.3890545070171356, 'f1': 0.6882390196568334}

Added lowercase checks to embeddings!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=26, tm_hour=20, tm_min=58, tm_sec=38, tm_wday=5, tm_yday=26, tm_isdst=0)
{'threshold': 0.37275412678718567, 'f1': 0.6857278512162217}

Removed words like SJWs and Coinbase that existed in embeddings from spellings 
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=27, tm_hour=0, tm_min=53, tm_sec=38, tm_wday=6, tm_yday=27, tm_isdst=0)
{'threshold': 0.3786667585372925, 'f1': 0.6854281607863136}

Added â€‹ to punctuation 
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=27, tm_hour=1, tm_min=47, tm_sec=1, tm_wday=6, tm_yday=27, tm_isdst=0)
{'threshold': 0.3669199049472809, 'f1': 0.6857574865677499}

Removed lowercase conversion during preprocessing!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=27, tm_hour=13, tm_min=53, tm_sec=37, tm_wday=6, tm_yday=27, tm_isdst=0)
{'threshold': 0.38040247559547424, 'f1': 0.6863048198002605}

Changed order of embeddings and combination of embeddings!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=27, tm_hour=17, tm_min=6, tm_sec=38, tm_wday=6, tm_yday=27, tm_isdst=0)
{'threshold': 0.3679611086845398, 'f1': 0.6808142906855353}

Changed order of embeddings and combination of embeddings to para first!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=3, tm_min=59, tm_sec=54, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.37365326285362244, 'f1': 0.6766173175970621}

Changed order of embeddings and combination of embeddings to glove first!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=12, tm_min=12, tm_sec=55, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.37498849630355835, 'f1': 0.6874071667285555}

Changed order of embeddings and combination of embeddings to glove first and fasttext second!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=16, tm_min=35, tm_sec=7, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.3636126220226288, 'f1': 0.6870089972737281}

Changed order of embeddings back to glove first and paragram second and removed word2vec!
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=17, tm_min=48, tm_sec=22, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.3786276876926422, 'f1': 0.6870853128797966}

"cleaner_embedding_submission.py" : New embedding cleaning with individual embedding creation (glove, para, fast)
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=19, tm_min=51, tm_sec=18, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.37517982721328735, 'f1': 0.6875249356731908}

"cleaner_embedding_submission.py" : Added cleaning for unknown words.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=20, tm_min=46, tm_sec=7, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.37300583720207214, 'f1': 0.6879437942352175}

"highest-cv-code.py" : Init run
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=28, tm_hour=22, tm_min=26, tm_sec=27, tm_wday=0, tm_yday=28, tm_isdst=0)
{'threshold': 0.38060420751571655, 'f1': 0.687872579319605}

"highest-cv-code.py" : Added multiproc and cleaned embedding
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=0, tm_min=55, tm_sec=34, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.4051169753074646, 'f1': 0.6886860990520067}

"cleaner_embedding_submission.py" : Changed embedding matrix creation for first 3 to old method. Similar to highest-cv code but with additional word2vec unique.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=14, tm_min=26, tm_sec=7, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.3760419189929962, 'f1': 0.6874848060382251}

"highest-cv-code.py" : Added multiproc and cleaned embedding rerun with int cleaner.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=15, tm_min=17, tm_sec=17, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.4051169753074646, 'f1': 0.6886860990520067}

"cleaner_embedding_submission.py" : Removed word2vec to verify similarity to highest-cv. (This: g, p, f) (Highest: p,w,g).
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=16, tm_min=10, tm_sec=11, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.3771056532859802, 'f1': 0.6867344506647599}

"cleaner_embedding_submission.py" : Changed embedding order from previous to match highest.(This: p, f, g) (Highest: p,f,g).
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=18, tm_min=38, tm_sec=53, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.3771056532859802, 'f1': 0.6867344506647599}

"highest-cv-code.py" : Added gaussian noise after concat layer.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=19, tm_min=32, tm_sec=35, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.35031864047050476, 'f1': 0.6877051105091035}

"cleaner_embedding_submission.py" : Added cleaning for unknown words rerun.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=21, tm_min=11, tm_sec=29, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 0.37300583720207214, 'f1': 0.6879437942352175}

"cleaner_embedding_submission.py" : Added incorrect weighted logit loss.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=29, tm_hour=23, tm_min=14, tm_sec=16, tm_wday=1, tm_yday=29, tm_isdst=0)
{'threshold': 3.734879214789544e-07, 'f1': 0.3485595090540826}

"cleaner_embedding_submission.py" : Noise after concat layer.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=0, tm_min=15, tm_sec=10, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.361013263463974, 'f1': 0.6872065253758206}

"cleaner_embedding_submission.py" : Noise after concat layer modified to 0.5<-0.1.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=1, tm_min=7, tm_sec=53, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.371946781873703, 'f1': 0.6854438936457864}

"cleaner_embedding_submission.py" : Noise after embedding and noise reverted to 0.1.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=4, tm_min=27, tm_sec=28, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.3538971543312073, 'f1': 0.6884909778896383}

"cleaner_embedding_submission.py" : Removed noise and 2nd gru block.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=15, tm_min=29, tm_sec=55, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.2979777753353119, 'f1': 0.6824095997793154}

"cleaner_embedding_submission.py" : Parallel grus & hidden size 60->32.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=16, tm_min=24, tm_sec=19, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.3701809346675873, 'f1': 0.6833384669925088}

"single_model.py" : 15 fixed, 6 train, 3 patience with new cleaning.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=19, tm_min=8, tm_sec=31, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.34906595945358276, 'f1': 0.6996606996606997}

"single_model.py" : 20 fixed, 2 train, 5 patience, 2% validation, with adaptive lr and no noise.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=19, tm_min=43, tm_sec=11, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.2818737030029297, 'f1': 0.7032905744562187}

"single_model.py" : 20 fixed, 2 train, 5 patience, 2% validation, with adaptive lr patience 2->1 and no noise.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=20, tm_min=14, tm_sec=26, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.40489262342453003, 'f1': 0.7005511328842621}

"single_model.py" : 20 fixed, 2 train, 5 patience, 2% validation, with adaptive lr patience=1 WITH noise after concat.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=21, tm_min=0, tm_sec=9, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.3248855173587799, 'f1': 0.7070245573957739}

"single_model.py" : 20 fixed, 2 train, 5 patience, 2% validation, with adaptive lr patience=2 WITH noise after concat.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=30, tm_hour=21, tm_min=41, tm_sec=6, tm_wday=2, tm_yday=30, tm_isdst=0)
{'threshold': 0.3815392851829529, 'f1': 0.7059854014598541}

"concat_embedding.py" : Init run (same as "cleaner_embedding".
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=31, tm_hour=13, tm_min=6, tm_sec=25, tm_wday=3, tm_yday=31, tm_isdst=0)
{'threshold': 0.37300583720207214, 'f1': 0.6879437942352175}

"concat_embedding.py" : Added concatenated embeddings.
time.struct_time(tm_year=2019, tm_mon=1, tm_mday=31, tm_hour=16, tm_min=36, tm_sec=7, tm_wday=3, tm_yday=31, tm_isdst=0)
{'threshold': 0.33709609508514404, 'f1': 0.6749715964515648}

time.struct_time(tm_year=2019, tm_mon=2, tm_mday=3, tm_hour=20, tm_min=57, tm_sec=4, tm_wday=6, tm_yday=34, tm_isdst=0)
{'threshold': 0.38060420751571655, 'f1': 0.687872579319605}

"early_stopping_init.py" : Added misspell dict corrections to previous. 0.6882738825005955 -> 0.688698707317496 on Kaggle.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=3, tm_hour=21, tm_min=59, tm_sec=9, tm_wday=6, tm_yday=34, tm_isdst=0)
{'threshold': 0.37550053000450134, 'f1': 0.6886204366489304}

"early_stopping_init.py" : Added clean unknown words to previous.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=3, tm_hour=23, tm_min=1, tm_sec=55, tm_wday=6, tm_yday=34, tm_isdst=0)
{'threshold': 0.37543734908103943, 'f1': 0.6880172682465111}

"early_stopping_init.py" : Removed rare words and lower case conversion. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=3, tm_hour=23, tm_min=54, tm_sec=14, tm_wday=6, tm_yday=34, tm_isdst=0)
{'threshold': 0.3815101385116577, 'f1': 0.6866308305878274}

"early_stopping_init.py" : Removed lower=False from tokenizer. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=0, tm_min=45, tm_sec=7, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.36576685309410095, 'f1': 0.6882516825076529}

"early_stopping_init.py" : Reverted to highest CV with parallel clean!. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=1, tm_min=42, tm_sec=56, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.37550053000450134, 'f1': 0.6886204366489304}

"early_stopping_init.py" : Added remove spaces and replaced punctuation clean. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=2, tm_min=40, tm_sec=55, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.38786882162094116, 'f1': 0.6858327606221087}

"early_stopping_init.py" : Added noise after concat layer. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=4, tm_min=21, tm_sec=41, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3504871726036072, 'f1': 0.6871995974388784}

"early_stopping_init.py" : Removed useless embedding line and noise to pool layers. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=5, tm_min=14, tm_sec=0, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3389705717563629, 'f1': 0.6876077823173342}

"early_stopping_init.py" : Reverted to highest CV and removed test words from tokenizer. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=14, tm_min=26, tm_sec=34, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.37342724204063416, 'f1': 0.6884971862673819}

"early_stopping_init.py" : Reverted to highest CV and max features to 100k <- 120k. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=16, tm_min=13, tm_sec=10, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3100065588951111, 'f1': 0.6863117870722434}

"early_stopping_init.py" : Reverted to highest CV and hidden size 60->64. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=17, tm_min=31, tm_sec=30, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3891199827194214, 'f1': 0.6867601814673828}

"early_stopping_init.py" : Reverted to highest CV and hidden size 60. 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=18, tm_min=29, tm_sec=57, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.37550053000450134, 'f1': 0.6886204366489304}

"early_stopping_init.py" : Made reduction to mean from sum 
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=20, tm_min=18, tm_sec=45, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3647271394729614, 'f1': 0.6878508973768983}

"early_stopping_init.py" : Adam with cyclic LR with no mods.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=21, tm_min=33, tm_sec=49, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.3595193922519684, 'f1': 0.6823974997966843}

"early_stopping_init.py" : Removed cyclic and Adam->Adadelta.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=22, tm_min=23, tm_sec=38, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.349122554063797, 'f1': 0.6798913232784144}

"early_stopping_init.py" : Reverted to Adam, decreased hidden size 60->50.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=23, tm_min=7, tm_sec=56, tm_wday=0, tm_yday=35, tm_isdst=0)
{'threshold': 0.34327536821365356, 'f1': 0.6844040392416353}

"early_stopping_init.py" : Reverted to highest.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=0, tm_min=5, tm_sec=24, tm_wday=1, tm_yday=36, tm_isdst=0)
{'threshold': 0.37550053000450134, 'f1': 0.6886204366489304}

"early_stopping_init.py" : Added Gaussian Noise to highest.
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=1, tm_min=21, tm_sec=54, tm_wday=1, tm_yday=36, tm_isdst=0)
{'threshold': 0.381486177444458, 'f1': 0.6893422449289056}

"early_stopping_init.py" : Added Gaussian Noise after concat too!
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=2, tm_min=18, tm_sec=11, tm_wday=1, tm_yday=36, tm_isdst=0)
{'threshold': 0.3727074861526489, 'f1': 0.689111606182053}

"early_stopping_init.py" : Removed Gaussian Noise after concat, changed std of embedding noise 0.1->0.2!
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=3, tm_min=10, tm_sec=57, tm_wday=1, tm_yday=36, tm_isdst=0)
{'threshold': 0.3610870838165283, 'f1': 0.6885027048362007}

"early_stopping_init.py" : Removed Gaussian Noise after concat, changed std of embedding noise 0.2->0.05!
time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=4, tm_min=12, tm_sec=26, tm_wday=1, tm_yday=36, tm_isdst=0)
{'threshold': 0.36497217416763306, 'f1': 0.6878625651971838}


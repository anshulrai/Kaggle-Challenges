{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nimport bz2\nimport gc\nimport chardet\nimport re\nimport os\nimport random\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "154e546a6339dc9b989782ba0f59cb5f7527efc9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.models import Model, Sequential\nfrom keras.layers import Dense, Embedding, Input, Conv1D, GlobalMaxPool1D, Dropout, concatenate, Layer, InputSpec, CuDNNLSTM\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras import activations, initializers, regularizers, constraints\nfrom keras.utils.conv_utils import conv_output_length\nfrom keras.regularizers import l2\nfrom keras.constraints import maxnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5cd38bcc85a438059143c5d3ce2c9db52ef924a3"
      },
      "cell_type": "markdown",
      "source": "# QRNN \n\nSource : https://github.com/DingKe/nn_playground/blob/master/qrnn/qrnn.py"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "c648655c0064ce329ad48023c2c43417b0b77f32",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def _dropout(x, level, noise_shape=None, seed=None):\n    x = K.dropout(x, level, noise_shape, seed)\n    x *= (1. - level) # compensate for the scaling by the dropout\n    return x\n\n\nclass QRNN(Layer):\n    '''Quasi RNN\n    # Arguments\n        units: dimension of the internal projections and the final output.\n    # References\n        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n    '''\n    def __init__(self, units, window_size=2, stride=1,\n                 return_sequences=False, go_backwards=False, \n                 stateful=False, unroll=False, activation='tanh',\n                 kernel_initializer='uniform', bias_initializer='zero',\n                 kernel_regularizer=None, bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None, bias_constraint=None, \n                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n                 **kwargs):\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.units = units \n        self.window_size = window_size\n        self.strides = (stride, 1)\n\n        self.use_bias = use_bias\n        self.activation = activations.get(activation)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = dropout\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.input_dim = input_dim\n        self.input_length = input_length\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_length, self.input_dim)\n        super(QRNN, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_dim = input_shape[2]\n        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n        self.state_spec = InputSpec(shape=(batch_size, self.units))\n\n        self.states = [None]\n        if self.stateful:\n            self.reset_states()\n\n        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n        self.kernel = self.add_weight(name='kernel',\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(name='bias', \n                                        shape=(self.units * 3,),\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        length = input_shape[1]\n        if length:\n            length = conv_output_length(length + self.window_size - 1,\n                                        self.window_size, 'valid',\n                                        self.strides[0])\n        if self.return_sequences:\n            return (input_shape[0], length, self.units)\n        else:\n            return (input_shape[0], self.units)\n\n    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            return mask\n        else:\n            return None\n\n    def get_initial_states(self, inputs):\n        # build an all-zero tensor of shape (samples, units)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n        initial_states = [initial_state for _ in range(len(self.states))]\n        return initial_states\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        if not self.input_spec:\n            raise RuntimeError('Layer has never been called '\n                               'and thus has no states.')\n\n        batch_size = self.input_spec.shape[0]\n        if not batch_size:\n            raise ValueError('If a QRNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 'state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, self.units)) +\n                                     ', found shape=' + str(value.shape))\n                K.set_value(state, value)\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is not None:\n            if hasattr(initial_state, '_keras_history'):\n                # Compute the full input spec, including state\n                input_spec = self.input_spec\n                state_spec = self.state_spec\n                if not isinstance(state_spec, list):\n                    state_spec = [state_spec]\n                self.input_spec = [input_spec] + state_spec\n\n                # Compute the full inputs, including state\n                if not isinstance(initial_state, (list, tuple)):\n                    initial_state = [initial_state]\n                inputs = [inputs] + list(initial_state)\n\n                # Perform the call\n                output = super(QRNN, self).__call__(inputs, **kwargs)\n\n                # Restore original input spec\n                self.input_spec = input_spec\n                return output\n            else:\n                kwargs['initial_state'] = initial_state\n        return super(QRNN, self).__call__(inputs, **kwargs)\n\n    def call(self, inputs, mask=None, initial_state=None, training=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_states = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_states = self.states\n        else:\n            initial_states = self.get_initial_states(inputs)\n\n        if len(initial_states) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_states)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        if self.unroll and input_shape[1] is None:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n\n        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n                                            initial_states,\n                                            go_backwards=self.go_backwards,\n                                            mask=mask,\n                                            constants=constants,\n                                            unroll=self.unroll,\n                                            input_length=input_shape[1])\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout < 1:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            return outputs\n        else:\n            return last_output\n\n    def preprocess_input(self, inputs, training=None):\n        if self.window_size > 1:\n            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n\n        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n                          padding='valid',\n                          data_format='channels_last')\n        output = K.squeeze(output, 2)  # remove the dummy dimension\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format='channels_last')\n\n        if self.dropout is not None and 0. < self.dropout < 1.:\n            z = output[:, :, :self.units]\n            f = output[:, :, self.units:2 * self.units]\n            o = output[:, :, 2 * self.units:]\n            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n            return K.concatenate([z, f, o], -1)\n        else:\n            return output\n\n    def step(self, inputs, states):\n        prev_output = states[0]\n\n        z = inputs[:, :self.units]\n        f = inputs[:, self.units:2 * self.units]\n        o = inputs[:, 2 * self.units:]\n\n        z = self.activation(z)\n        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n        o = K.sigmoid(o)\n\n        output = f * prev_output + (1 - f) * z\n        output = o * output\n\n        return output, [output]\n\n    def get_constants(self, inputs, training=None):\n        return []\n \n    def get_config(self):\n        config = {'units': self.units,\n                  'window_size': self.window_size,\n                  'stride': self.strides[0],\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'use_bias': self.use_bias,\n                  'dropout': self.dropout,\n                  'activation': activations.serialize(self.activation),\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'input_dim': self.input_dim,\n                  'input_length': self.input_length}\n        base_config = super(QRNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02f87a43fa13afb0f3979861f717749c0e371382"
      },
      "cell_type": "markdown",
      "source": "# Read Train & Test Files"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_file = bz2.BZ2File('../input/train.ft.txt.bz2')\ntest_file = bz2.BZ2File('../input/test.ft.txt.bz2')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1c8b75a3-0a27-4b11-84b3-fa84c0142022",
        "_uuid": "a42d697da87a52f6830aafec878ea97e58b8e374"
      },
      "cell_type": "markdown",
      "source": "# Create Lists containing Train & Test sentences"
    },
    {
      "metadata": {
        "_cell_guid": "d554f2ba-0eeb-4764-b1df-febfbdda5c2c",
        "_uuid": "93213b70d17edcdeeba304a7344e415733d0ce17",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_file_lines = train_file.readlines()\ntest_file_lines = test_file.readlines()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0dcd02dc26e3ffaea4ea8e35a43dbb329ca81747"
      },
      "cell_type": "code",
      "source": "del train_file, test_file",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "561793e5-67c7-4768-afbf-d1e35c2babfa",
        "_uuid": "2a3a3396c7460ce53c2e11a997d4115118b49b56"
      },
      "cell_type": "markdown",
      "source": "# Convert from raw binary strings to strings that can be parsed"
    },
    {
      "metadata": {
        "_cell_guid": "ceda406d-42f3-46de-930c-f658b1090792",
        "_uuid": "5758abb69d2f0b7434041d5444916089ef468d88",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\ntest_file_lines = [x.decode('utf-8') for x in test_file_lines]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "59bcdb63-c433-4a77-806a-90d152a077df",
        "_uuid": "1de1d8a747b4ab76cce6076f5b2e0b79c291cf53"
      },
      "cell_type": "markdown",
      "source": "# Check Data Appearance"
    },
    {
      "metadata": {
        "_cell_guid": "722d7d54-ccb9-4c61-8a10-c51f1b6b6799",
        "_uuid": "6871367413ee2b3fec9d6e39deb4b662e0f1458d",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "random.sample(train_file_lines, 10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "846931d3-7905-4d8d-b58f-3b5c036936e0",
        "_uuid": "c72c77a030d98b6aa8b25c2332da7eb8675d7505"
      },
      "cell_type": "markdown",
      "source": "From the above output it can be seen that each sentence begins with it's sentiment **(__label__1 -> Negative, __label__2 -> Positive)**, which is then followed by the review and ends with a newline character **\\n**. \n\nSo, first I go convert all the labels to **O**(Negative) and **1**(Positive) and store it in lists that only contain the label values. After this, I store the remainder of the sentence excluding the newline character in lowercase in lists. Also, convert all numbers to **0**."
    },
    {
      "metadata": {
        "_cell_guid": "23ca79f9-747f-4815-9f9b-6bafd4141f42",
        "_uuid": "dedf1e6f5e90b63fca7d51e63673f9a96d171417"
      },
      "cell_type": "markdown",
      "source": "# Clean Data"
    },
    {
      "metadata": {
        "_cell_guid": "dcc69630-91ef-4a06-9eb4-56c4b0390a49",
        "_uuid": "539afb8a439f11442ad8ca5c1de042a3a310462f",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Make everything Lower Case\n\ntrain_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\ntrain_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]\n\nfor i in range(len(train_sentences)):\n    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n    \ntest_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\ntest_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n\nfor i in range(len(test_sentences)):\n    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n\n# Modify URLs to <url>\n\nfor i in range(len(train_sentences)):\n    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n        \nfor i in range(len(test_sentences)):\n    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "15947711-c1fa-41d0-955e-0eefa19e15bf",
        "_uuid": "b92d23679d94f3bf2926d8e0ed97999552d05d9b"
      },
      "cell_type": "markdown",
      "source": "# Data before cleaning"
    },
    {
      "metadata": {
        "_cell_guid": "85b281db-34b5-47cf-bf71-7789e3ed2aae",
        "_uuid": "62e8111debc8ffbd237d67cdcc1b4f13b650f440",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_file_lines[70:75]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fd11e294-5fd9-46d4-98bc-228327252707",
        "_uuid": "cccd7a6924417c46a1307c19e0540493aee83be0"
      },
      "cell_type": "markdown",
      "source": "# Data After Cleaning"
    },
    {
      "metadata": {
        "_cell_guid": "d5822e4e-4488-479e-89ce-e3e6ade8e79f",
        "_uuid": "cfa9fdd07f77c7c3bbc9858e00497b0e03f45a58",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_sentences[70:75]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f50af038-57c1-405e-a503-2f21d955df37",
        "_uuid": "1e3149b1541e02b2b4a20c06cb386eaa377186c5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_labels[70:75]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "collapsed": true,
        "_uuid": "56fd3c360436e6af71a74afd4630c9b38622efd1"
      },
      "cell_type": "code",
      "source": "del train_file_lines, test_file_lines",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "03b49435-b06b-4f72-b8f2-27faae8cf478",
        "_uuid": "3754d4d288fe5411ee0cc26112a17dd34a6e427c",
        "scrolled": true,
        "trusted": true,
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "gc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0fc903850a2733d56886c79adca66ddd5b196a39"
      },
      "cell_type": "markdown",
      "source": "# Text Preprocessing"
    },
    {
      "metadata": {
        "_cell_guid": "5798589b-1ee6-45a1-9060-6d8d80a30dc2",
        "_uuid": "622e996b36bbd4b0b7066a16539b0bbab35654c1",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "max_features = 20000\nmaxlen = 100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6b136d305a8e73f75fe08711e43914da2599d3d5"
      },
      "cell_type": "code",
      "source": "tokenizer = text.Tokenizer(num_words=max_features)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1d2f085bc31c38c7f3af0fca2c1fd4779b8a1e42"
      },
      "cell_type": "code",
      "source": "tokenizer.fit_on_texts(train_sentences)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4d806975158da7dfd69eb8006645a2cc754a4991"
      },
      "cell_type": "code",
      "source": "tokenized_train = tokenizer.texts_to_sequences(train_sentences)\nX_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd86afe1e8def80962e3cf4e82216cf1ea3826cb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X_train[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "03f26adbb08377749f90e8f4f9beb2124c90237b"
      },
      "cell_type": "code",
      "source": "tokenized_test = tokenizer.texts_to_sequences(test_sentences)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "792c20199703383c44801aa9fdade1a170b77ee6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "del tokenized_test, tokenized_train, tokenizer, train_sentences, test_sentences\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "13efa17891b72dbbf051ad72ce362196902cbf82"
      },
      "cell_type": "markdown",
      "source": "# Define QRNN Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38f5f4b1ad7995f5d28619f997e2b85091c99744",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def qrnn_model(conv_layers = 2, max_dilation_rate = 3):\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Dropout(0.25)(x)\n    x = Conv1D(2*embed_size, kernel_size = 3)(x)\n    prefilt = Conv1D(2*embed_size, kernel_size = 3)(x)\n    x = prefilt\n    for strides in [1, 1, 2]:\n        x = QRNN(128*2**(strides), return_sequences = True, stride = strides, dropout = 0.2, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n    x_f = QRNN(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10) )(x)  \n    x_b = QRNN(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10), go_backwards=True)(x)\n    x = concatenate([x_f, x_b])\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['binary_accuracy'])\n\n    return model\n\nqrnn_model = qrnn_model()\nqrnn_model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "714c2298a671aeb409ec8fb57989af18fa6c414a"
      },
      "cell_type": "code",
      "source": "batch_size = 2048\nepochs = 4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "accd1adfe7f9b77470cb772675c79aee4bf76cd7"
      },
      "cell_type": "code",
      "source": "weight_path=\"early_weights.hdf5\"\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\ncallbacks = [checkpoint, early_stopping]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ec539c474f4577de22b3d9eeae822e5d1f8d3df3"
      },
      "cell_type": "markdown",
      "source": "# Train the model\n\nIn this case, I'm just using a part of the dataset to save execution time"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf636bd7257f723dd67eecb7138acd5137db6050",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "qrnn_model.fit(X_train[:100000], train_labels[:100000], batch_size=batch_size, epochs=epochs, shuffle = True, validation_split=0.20, callbacks=callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc5bb488724f66209626367c5604a5121e76dc11"
      },
      "cell_type": "markdown",
      "source": "# Test the model\n\nOn full dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b73143c1ec56596090e6ef2089be4846f225321a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "qrnn_model.load_weights(weight_path)\nscore, acc = qrnn_model.evaluate(X_test, test_labels, batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "da52398861b29bfa222099fbaef69f45cd824adf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
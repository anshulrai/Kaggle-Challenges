{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport gc\nimport time\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport matplotlib.pyplot as plt\nimport shap\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom IPython.display import HTML\nimport base64\nimport featuretools as ft\nimport os\nprint(os.listdir(\"../input\"))\nfrom sklearn.preprocessing import StandardScaler\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'sample_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2477c8e18b863d71aec00ab08485bdd3ac198dbe"
      },
      "cell_type": "code",
      "source": "gc.enable()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23d5f6348dacef97e76129b60cca4765af067e11"
      },
      "cell_type": "code",
      "source": "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name):\n    \n    model = lgb.LGBMClassifier(max_depth=-1,\n                               n_estimators=999999,\n                               learning_rate=0.02,\n                               colsample_bytree=0.3,\n                               num_leaves=2,\n                               metric='auc',\n                               objective='binary', \n                               n_jobs=-1)\n     \n    model.fit(X_fit, y_fit, \n              eval_set=[(X_val, y_val)],\n              verbose=0, \n              early_stopping_rounds=3000)\n                  \n    cv_val = model.predict_proba(X_val)[:,1]\n    \n    #Save LightGBM Model\n    save_to = '{}{}_fold{}.txt'.format(lgb_path, name, counter+1)\n    model.booster_.save_model(save_to)\n    \n    return cv_val",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bddf79f364a5af60918a509fc89676c4cfaddb5e"
      },
      "cell_type": "code",
      "source": "def fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name):\n    \n    model = xgb.XGBClassifier(max_depth=6,\n                              n_estimators=999999,\n                              colsample_bytree=0.3,\n                              learning_rate=0.05,\n                              objective='binary:logistic', \n                              n_jobs=-1)\n     \n    model.fit(X_fit, y_fit, \n              eval_set=[(X_val, y_val)], \n              verbose=0, \n              early_stopping_rounds=100)\n              \n    cv_val = model.predict_proba(X_val)[:,1]\n    \n    #Save XGBoost Model\n    save_to = '{}{}_fold{}.dat'.format(xgb_path, name, counter+1)\n    pickle.dump(model, open(save_to, \"wb\"))\n    \n    return cv_val",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7076f60924ec0238974c1e1315dbecc48bd2223d"
      },
      "cell_type": "code",
      "source": "def fit_cb(X_fit, y_fit, X_val, y_val, counter, cb_path, name):\n    \n    model = cb.CatBoostClassifier(iterations=999999,\n                                  learning_rate=0.05,\n                                  colsample_bylevel=0.03,\n                                  objective=\"Logloss\")\n                                  \n    model.fit(X_fit, y_fit, \n              eval_set=[(X_val, y_val)], \n              verbose=0, early_stopping_rounds=100)\n              \n    cv_val = model.predict_proba(X_val)[:,1]\n    \n    #Save Catboost Model          \n    save_to = \"{}{}_fold{}.mlmodel\".format(cb_path, name, counter+1)\n    model.save_model(save_to, format=\"coreml\", \n                     export_parameters={'prediction_type': 'probability'})\n                     \n    return cv_val",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9262be2c3bd24d2cea46f3c11398d40c1d1048cd"
      },
      "cell_type": "code",
      "source": "def train_stage(df_path, lgb_path, xgb_path, cb_path):\n    \n    print('Load Train Data.')\n    df = reduce_mem_usage(pd.read_csv(df_path))\n    print('\\nShape of Train Data: {}'.format(df.shape))\n    \n    y_df = np.array(df['target'])                        \n    df_ids = np.array(df.index)                     \n    df.drop(['ID_code', 'target'], axis=1, inplace=True)\n    \n    lgb_cv_result = np.zeros(df.shape[0])\n    xgb_cv_result = np.zeros(df.shape[0])\n    cb_cv_result  = np.zeros(df.shape[0])\n    \n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    skf.get_n_splits(df_ids, y_df)\n    \n    print('\\nModel Fitting...')\n    for counter, ids in enumerate(skf.split(df_ids, y_df)):\n        print('\\nFold {}'.format(counter+1))\n        X_fit, y_fit = df.values[ids[0]], y_df[ids[0]]\n        X_val, y_val = df.values[ids[1]], y_df[ids[1]]\n    \n        print('LigthGBM')\n        lgb_cv_result[ids[1]] += fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name='lgb')\n        print('XGBoost')\n        xgb_cv_result[ids[1]] += fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name='xgb')\n        print('CatBoost')\n        cb_cv_result[ids[1]]  += fit_cb(X_fit,  y_fit, X_val, y_val, counter, cb_path,  name='cb')\n        \n        del X_fit, X_val, y_fit, y_val\n        gc.collect()\n    \n    auc_lgb  = round(roc_auc_score(y_df, lgb_cv_result),4)\n    auc_xgb  = round(roc_auc_score(y_df, xgb_cv_result),4)\n    auc_cb   = round(roc_auc_score(y_df, cb_cv_result), 4)\n    auc_mean = round(roc_auc_score(y_df, (lgb_cv_result+xgb_cv_result+cb_cv_result)/3), 4)\n    auc_mean_lgb_cb = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result)/2), 4)\n    print('\\nLightGBM VAL AUC: {}'.format(auc_lgb))\n    print('XGBoost  VAL AUC: {}'.format(auc_xgb))\n    print('Catboost VAL AUC: {}'.format(auc_cb))\n    print('Mean Catboost+LightGBM VAL AUC: {}'.format(auc_mean_lgb_cb))\n    print('Mean XGBoost+Catboost+LightGBM, VAL AUC: {}\\n'.format(auc_mean))\n    \n    return 0",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "405d732eb15394ed8a3f48b0f700cf25f26d44b9"
      },
      "cell_type": "code",
      "source": "def prediction_stage(df_path, lgb_path, xgb_path, cb_path):\n    \n    print('Load Test Data.')\n    df = reduce_mem_usage(pd.read_csv(df_path))\n    print('\\nShape of Test Data: {}'.format(df.shape))\n    \n    df.drop(['ID_code'], axis=1, inplace=True)\n    \n    lgb_models = sorted(os.listdir(lgb_path))\n    xgb_models = sorted(os.listdir(xgb_path))\n    cb_models  = sorted(os.listdir(cb_path))\n    \n    lgb_result = np.zeros(df.shape[0])\n    xgb_result = np.zeros(df.shape[0])\n    cb_result  = np.zeros(df.shape[0])\n    \n    print('\\nMake predictions...\\n')\n    \n    print('With LightGBM...')\n    for m_name in lgb_models:\n        #Load LightGBM Model\n        model = lgb.Booster(model_file='{}{}'.format(lgb_path, m_name))\n        lgb_result += model.predict(df.values)\n     \n    print('With XGBoost...')    \n    for m_name in xgb_models:\n        #Load Catboost Model\n        model = pickle.load(open('{}{}'.format(xgb_path, m_name), \"rb\"))\n        xgb_result += model.predict(df.values)\n    \n    print('With CatBoost...')        \n    for m_name in cb_models:\n        #Load Catboost Model\n        model = cb.CatBoostClassifier()\n        model = model.load_model('{}{}'.format(cb_path, m_name), format = 'coreml')\n        cb_result += model.predict(df.values, prediction_type='Probability')[:,1]\n    \n    lgb_result /= len(lgb_models)\n    xgb_result /= len(xgb_models)\n    cb_result  /= len(cb_models)\n    \n    submission = pd.read_csv('../input/sample_submission.csv')\n    submission['target'] = (lgb_result+xgb_result+cb_result)/3\n    submission.to_csv('xgb_lgb_cb_starter_submission.csv', index=False)\n    submission['target'] = (lgb_result+cb_result)/2\n    submission.to_csv('lgb_cb_starter_submission.csv', index=False)\n    submission['target'] = xgb_result\n    submission.to_csv('xgb_starter_submission.csv', index=False)\n    submission['target'] = lgb_result\n    submission.to_csv('lgb_starter_submission.csv', index=False)\n    submission['target'] = cb_result\n    submission.to_csv('cb_starter_submission.csv', index=False)\n    \n    return 0",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "763f1e9d06cfc450a92cda612eaed0759a23e4f5"
      },
      "cell_type": "code",
      "source": "train_path = '../input/train.csv'\ntest_path  = '../input/test.csv'\n\nlgb_path = './lgb_models_stack/'\nxgb_path = './xgb_models_stack/'\ncb_path  = './cb_models_stack/'\n\n#Create dir for models\nos.mkdir(lgb_path)\nos.mkdir(xgb_path)\nos.mkdir(cb_path)\n\nprint('Train Stage.\\n')\ntrain_stage(train_path, lgb_path, xgb_path, cb_path)\n\nprint('Prediction Stage.\\n')\nprediction_stage(test_path, lgb_path, xgb_path, cb_path)\n\nprint('\\nDone.')",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train Stage.\n\nLoad Train Data.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08169384d00d542c7ffc4e3b4f25fca131fef825"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}